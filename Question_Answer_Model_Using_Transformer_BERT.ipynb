{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fNXhyiAAtGcB"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "df=messages = pd.read_csv('SMSSpamCollection', sep='\\t',\n",
        "                           names=[\"label\", \"message\"])\n",
        "df.head()\n",
        "df.shape\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X=list(df['message'])\n",
        "\n",
        "\n",
        "y=list(df['label'])\n",
        "\n",
        "\n",
        "y"
      ],
      "metadata": {
        "id": "29hAYcKFtYGX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y=list(pd.get_dummies(y,drop_first=True)['spam'])\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 0)"
      ],
      "metadata": {
        "id": "Ai1PoH-rtZRM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "id": "A3X6Krpbtfmd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import DistilBertTokenizerFast\n",
        "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')\n"
      ],
      "metadata": {
        "id": "199H3LQHto1H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_encodings = tokenizer(X_train, truncation=True, padding=True)\n",
        "test_encodings = tokenizer(X_test, truncation=True, padding=True)\n",
        "\n",
        "\n",
        "y_train"
      ],
      "metadata": {
        "id": "AEEfcCOBts7p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((\n",
        "    dict(train_encodings),\n",
        "    y_train\n",
        "))\n",
        "\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((\n",
        "    dict(test_encodings),\n",
        "    y_test\n",
        "))"
      ],
      "metadata": {
        "id": "-wS8Ppo-twX1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TFDistilBertForSequenceClassification, TFTrainer, TFTrainingArguments\n",
        "\n",
        "training_args = TFTrainingArguments(\n",
        "    output_dir='./results',          # output directory\n",
        "    num_train_epochs=2,              # total number of training epochs\n",
        "    per_device_train_batch_size=8,  # batch size per device during training\n",
        "    per_device_eval_batch_size=16,   # batch size for evaluation\n",
        "    warmup_steps=500,                # number of warmup steps for learning rate scheduler\n",
        "    weight_decay=0.01,               # strength of weight decay\n",
        "    logging_dir='./logs',            # directory for storing logs\n",
        "    logging_steps=10,\n",
        ")"
      ],
      "metadata": {
        "id": "btspaUbrt1uk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with training_args.strategy.scope():\n",
        "    model = TFDistilBertForSequenceClassification.from_pretrained(\"distilbert-base-uncased\")\n",
        "\n",
        "trainer = TFTrainer(\n",
        "    model=model,                         # the instantiated ðŸ¤— Transformers model to be trained\n",
        "    args=training_args,                  # training arguments, defined above\n",
        "    train_dataset=train_dataset,         # training dataset\n",
        "    eval_dataset=test_dataset             # evaluation dataset\n",
        ")\n",
        "\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "a2diLlcrt5Bi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.evaluate(test_dataset)"
      ],
      "metadata": {
        "id": "NdilTqZ3t_eE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.predict(test_dataset)"
      ],
      "metadata": {
        "id": "PaCVDSKCuAQq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.predict(test_dataset)[1].shape"
      ],
      "metadata": {
        "id": "rOkcnBDruCtk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.predict(test_dataset)[1].shape"
      ],
      "metadata": {
        "id": "BhOdZ17JuHdz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output=trainer.predict(test_dataset)[1]\n",
        "\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "cm=confusion_matrix(y_test,output)\n",
        "cm"
      ],
      "metadata": {
        "id": "R7adgGI4uKNQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.save_model('senti_model')"
      ],
      "metadata": {
        "id": "fEtBcr8xuPaH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}